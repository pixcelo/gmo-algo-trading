{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_names):\n",
    "    dfs = []\n",
    "    for file_name in file_names:\n",
    "        df = pd.read_csv(file_name)\n",
    "        dfs.append(df)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df, prefix):\n",
    "    open = df[f'{prefix}_open'].values\n",
    "    high = df[f'{prefix}_high'].values\n",
    "    low = df[f'{prefix}_low'].values\n",
    "    close = df[f'{prefix}_close'].values\n",
    "    volume = df[f'{prefix}_volume'].values\n",
    "    hilo = (high + low) / 2\n",
    "\n",
    "    df[f'{prefix}_RSI_ST'] = talib.RSI(close)/close\n",
    "    df[f'{prefix}_RSI_LOG'] = log_transform_feature(talib.RSI(close))\n",
    "    df[f'{prefix}_MACD'], _, _ = talib.MACD(close)\n",
    "    df[f'{prefix}_MACD_ST'], _, _ = talib.MACD(close)/close\n",
    "    df[f'{prefix}_ATR'] = talib.ATR(high, low, close)\n",
    "    df[f'{prefix}_ADX'] = talib.ADX(high, low, close, timeperiod=14)\n",
    "    df[f'{prefix}_ADXR'] = talib.ADXR(high, low, close, timeperiod=14)\n",
    "    \n",
    "    df[f'{prefix}_SMA10'] = talib.SMA(close, timeperiod=10)\n",
    "    df[f'{prefix}_SMA50'] = talib.SMA(close, timeperiod=50)\n",
    "    df[f'{prefix}_SMA200'] = talib.SMA(close, timeperiod=200)\n",
    "    \n",
    "    df[f'{prefix}_BB_UPPER'], df[f'{prefix}_BB_MIDDLE'], df[f'{prefix}_BB_LOWER'] = talib.BBANDS(close)\n",
    "    df[f'{prefix}_BBANDS_upperband'] = (df[f'{prefix}_BB_UPPER'] - hilo) / close\n",
    "    df[f'{prefix}_BBANDS_middleband'] = (df[f'{prefix}_BB_MIDDLE'] - hilo) / close\n",
    "    df[f'{prefix}_BBANDS_lowerband'] = (df[f'{prefix}_BB_LOWER'] - hilo) / close\n",
    "    df[f'{prefix}_STOCH_K'], df[f'{prefix}_STOCH_D'] = talib.STOCH(high, low, close)/close\n",
    "    df[f'{prefix}_MON'] = talib.MOM(close, timeperiod=5)\n",
    "    df[f'{prefix}_OBV'] = talib.OBV(close, volume)\n",
    "\n",
    "    df = df.dropna()\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def log_transform_feature(X):\n",
    "    X[X <= 0] = np.finfo(float).eps\n",
    "    return np.log(X)\n",
    "\n",
    "def create_label(df, prefix, lookahead=1):\n",
    "    df[f'{prefix}_target'] = (df[f'{prefix}_close'].shift(-lookahead) > df[f'{prefix}_close']).astype(int)\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(evals_result):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "    ax.plot(np.arange(len(evals_result['training']['binary_error'])),\n",
    "            evals_result['training']['binary_error'], label='Training')\n",
    "    ax.plot(np.arange(len(evals_result['valid_1']['binary_error'])),\n",
    "            evals_result['valid_1']['binary_error'], label='Validation')\n",
    "    ax.set_title('Learning Curve')\n",
    "    ax.set_xlabel('Iteration')\n",
    "    ax.set_ylabel('Binary Error')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_feature_importance(importances, feature_names):\n",
    "    importance = pd.DataFrame({\"Feature\": feature_names,\n",
    "                               \"Importance\": importances})\n",
    "    importance.sort_values(by=\"Importance\", ascending=False, inplace=True)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    sns.barplot(x=\"Importance\", y=\"Feature\", data=importance)\n",
    "    plt.title(\"Feature Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    features = df.drop(\"5m_target\", axis=1)\n",
    "    labels = df[\"5m_target\"]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    return X_train, X_val, y_train, y_val\n",
    "\n",
    "def train_and_evaluate(df, n_splits=5):\n",
    "    features = df.drop(['5m_target'], axis=1)\n",
    "    labels = df['5m_target']\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    feature_importances = []\n",
    "\n",
    "    for train_index, test_index in kf.split(features):\n",
    "        X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "        y_train, y_test = labels.iloc[train_index], labels.iloc[test_index]\n",
    "\n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        test_data = lgb.Dataset(X_test, label=y_test)\n",
    "\n",
    "        params = {\n",
    "            'objective': 'binary',\n",
    "            'metric': 'binary_error',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9\n",
    "        }\n",
    "\n",
    "        evals_result = {}\n",
    "\n",
    "        model = lgb.train(\n",
    "            params=params,\n",
    "            train_set=train_data,\n",
    "            valid_sets=[train_data, test_data],\n",
    "            num_boost_round=10000,\n",
    "            callbacks=[\n",
    "                lgb.callback.early_stopping(10),\n",
    "                lgb.callback.log_evaluation(period=100),\n",
    "                lgb.callback.record_evaluation(evals_result)\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred = np.round(y_pred).astype(int)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        plot_learning_curve(evals_result)\n",
    "        feature_importances.append(model.feature_importance())\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    print(f\"Mean accuracy: {mean_accuracy}\")\n",
    "\n",
    "    mean_importance = np.mean(feature_importances, axis=0)\n",
    "    plot_feature_importance(mean_importance, features.columns)\n",
    "\n",
    "    return model, evals_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_data(df):\n",
    "    # Set the date column as the index\n",
    "    df.set_index('date', inplace=True)\n",
    "    \n",
    "    # Convert the index to datetime\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    # Resample data to different timeframes\n",
    "    timeframes = ['1T', '15T', '1H', '4H', '1D']\n",
    "\n",
    "    resampled_dfs = []\n",
    "\n",
    "    for tf in timeframes:\n",
    "        resampled = df.resample(tf).agg({'open_bid': 'first', 'high_bid': 'max', 'low_bid': 'min', 'close_bid': 'last',\n",
    "                                         'open_ask': 'first', 'high_ask': 'max', 'low_ask': 'min', 'close_ask': 'last'})\n",
    "        resampled.dropna(inplace=True)\n",
    "        resampled.columns = [f\"{tf}_{col}\" for col in resampled.columns]\n",
    "        resampled_dfs.append(resampled)\n",
    "\n",
    "    # Combine resampled data\n",
    "    combined_resampled = pd.concat(resampled_dfs, axis=1).dropna()\n",
    "    return combined_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39m# Assuming you have only one DataFrame in the list\u001b[39;00m\n\u001b[1;32m      6\u001b[0m combined_df \u001b[39m=\u001b[39m dfs[\u001b[39m0\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m combined_df \u001b[39m=\u001b[39m resample_data(combined_df)\n\u001b[1;32m      8\u001b[0m display(combined_df)\n\u001b[1;32m     10\u001b[0m \u001b[39m# model, evals_result = train_and_evaluate(combined_df)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m# model_path = os.path.join(\"model\", \"test_model.pkl\")\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39m# with open(model_path, \"wb\") as f:\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m#     pickle.dump(model, f)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[39m# print(f\"Model saved to {model_path}\")\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m, in \u001b[0;36mresample_data\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      7\u001b[0m resampled_dfs \u001b[39m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m tf \u001b[39min\u001b[39;00m timeframes:\n\u001b[0;32m---> 10\u001b[0m     resampled \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mresample(tf)\u001b[39m.\u001b[39magg({\u001b[39m'\u001b[39m\u001b[39mopen_bid\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhigh_bid\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlow_bid\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mclose_bid\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mlast\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m                                      \u001b[39m'\u001b[39m\u001b[39mopen_ask\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhigh_ask\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlow_ask\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mclose_ask\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mlast\u001b[39m\u001b[39m'\u001b[39m})\n\u001b[1;32m     12\u001b[0m     resampled\u001b[39m.\u001b[39mdropna(inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     13\u001b[0m     resampled\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m [\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mtf\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mcol\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m resampled\u001b[39m.\u001b[39mcolumns]\n",
      "File \u001b[0;32m~/dev/python/gmo-algo-trading/myenv/lib/python3.11/site-packages/pandas/core/frame.py:10994\u001b[0m, in \u001b[0;36mDataFrame.resample\u001b[0;34m(self, rule, axis, closed, label, convention, kind, on, level, origin, offset, group_keys)\u001b[0m\n\u001b[1;32m  10979\u001b[0m \u001b[39m@doc\u001b[39m(NDFrame\u001b[39m.\u001b[39mresample, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_shared_doc_kwargs)\n\u001b[1;32m  10980\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mresample\u001b[39m(\n\u001b[1;32m  10981\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10992\u001b[0m     group_keys: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m  10993\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Resampler:\n\u001b[0;32m> 10994\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mresample(\n\u001b[1;32m  10995\u001b[0m         rule\u001b[39m=\u001b[39;49mrule,\n\u001b[1;32m  10996\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m  10997\u001b[0m         closed\u001b[39m=\u001b[39;49mclosed,\n\u001b[1;32m  10998\u001b[0m         label\u001b[39m=\u001b[39;49mlabel,\n\u001b[1;32m  10999\u001b[0m         convention\u001b[39m=\u001b[39;49mconvention,\n\u001b[1;32m  11000\u001b[0m         kind\u001b[39m=\u001b[39;49mkind,\n\u001b[1;32m  11001\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[1;32m  11002\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m  11003\u001b[0m         origin\u001b[39m=\u001b[39;49morigin,\n\u001b[1;32m  11004\u001b[0m         offset\u001b[39m=\u001b[39;49moffset,\n\u001b[1;32m  11005\u001b[0m         group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[1;32m  11006\u001b[0m     )\n",
      "File \u001b[0;32m~/dev/python/gmo-algo-trading/myenv/lib/python3.11/site-packages/pandas/core/generic.py:8895\u001b[0m, in \u001b[0;36mNDFrame.resample\u001b[0;34m(self, rule, axis, closed, label, convention, kind, on, level, origin, offset, group_keys)\u001b[0m\n\u001b[1;32m   8892\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mresample\u001b[39;00m \u001b[39mimport\u001b[39;00m get_resampler\n\u001b[1;32m   8894\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m-> 8895\u001b[0m \u001b[39mreturn\u001b[39;00m get_resampler(\n\u001b[1;32m   8896\u001b[0m     cast(\u001b[39m\"\u001b[39;49m\u001b[39mSeries | DataFrame\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mself\u001b[39;49m),\n\u001b[1;32m   8897\u001b[0m     freq\u001b[39m=\u001b[39;49mrule,\n\u001b[1;32m   8898\u001b[0m     label\u001b[39m=\u001b[39;49mlabel,\n\u001b[1;32m   8899\u001b[0m     closed\u001b[39m=\u001b[39;49mclosed,\n\u001b[1;32m   8900\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   8901\u001b[0m     kind\u001b[39m=\u001b[39;49mkind,\n\u001b[1;32m   8902\u001b[0m     convention\u001b[39m=\u001b[39;49mconvention,\n\u001b[1;32m   8903\u001b[0m     key\u001b[39m=\u001b[39;49mon,\n\u001b[1;32m   8904\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   8905\u001b[0m     origin\u001b[39m=\u001b[39;49morigin,\n\u001b[1;32m   8906\u001b[0m     offset\u001b[39m=\u001b[39;49moffset,\n\u001b[1;32m   8907\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[1;32m   8908\u001b[0m )\n",
      "File \u001b[0;32m~/dev/python/gmo-algo-trading/myenv/lib/python3.11/site-packages/pandas/core/resample.py:1523\u001b[0m, in \u001b[0;36mget_resampler\u001b[0;34m(obj, kind, **kwds)\u001b[0m\n\u001b[1;32m   1519\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1520\u001b[0m \u001b[39mCreate a TimeGrouper and return our resampler.\u001b[39;00m\n\u001b[1;32m   1521\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1522\u001b[0m tg \u001b[39m=\u001b[39m TimeGrouper(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m-> 1523\u001b[0m \u001b[39mreturn\u001b[39;00m tg\u001b[39m.\u001b[39;49m_get_resampler(obj, kind\u001b[39m=\u001b[39;49mkind)\n",
      "File \u001b[0;32m~/dev/python/gmo-algo-trading/myenv/lib/python3.11/site-packages/pandas/core/resample.py:1713\u001b[0m, in \u001b[0;36mTimeGrouper._get_resampler\u001b[0;34m(self, obj, kind)\u001b[0m\n\u001b[1;32m   1704\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(ax, TimedeltaIndex):\n\u001b[1;32m   1705\u001b[0m     \u001b[39mreturn\u001b[39;00m TimedeltaIndexResampler(\n\u001b[1;32m   1706\u001b[0m         obj,\n\u001b[1;32m   1707\u001b[0m         timegrouper\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1710\u001b[0m         gpr_index\u001b[39m=\u001b[39max,\n\u001b[1;32m   1711\u001b[0m     )\n\u001b[0;32m-> 1713\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   1714\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mOnly valid with DatetimeIndex, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1715\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mTimedeltaIndex or PeriodIndex, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1716\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got an instance of \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(ax)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1717\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    file_names = [\"combined_data.csv\"]\n",
    "    dfs = load_data(file_names)\n",
    "    \n",
    "    # Assuming you have only one DataFrame in the list\n",
    "    combined_df = dfs[0]\n",
    "    combined_df = resample_data(combined_df)\n",
    "    display(combined_df)\n",
    "\n",
    "    # model, evals_result = train_and_evaluate(combined_df)\n",
    "    # model_path = os.path.join(\"model\", \"test_model.pkl\")\n",
    "    # with open(model_path, \"wb\") as f:\n",
    "    #     pickle.dump(model, f)\n",
    "\n",
    "    # print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
