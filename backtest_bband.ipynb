{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m1/5dpmkc_567gddy0b98vly1w40000gn/T/ipykernel_47176/1871443153.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{short_prefix}_close_to_{long_prefix}_support'] = (short_close - long_support) / long_support\n",
      "/var/folders/m1/5dpmkc_567gddy0b98vly1w40000gn/T/ipykernel_47176/1871443153.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{short_prefix}_close_to_{long_prefix}_resistance'] = (short_close - long_resistance) / long_resistance\n",
      "/var/folders/m1/5dpmkc_567gddy0b98vly1w40000gn/T/ipykernel_47176/1871443153.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{short_prefix}_close_to_{long_prefix}_support'] = (short_close - long_support) / long_support\n",
      "/var/folders/m1/5dpmkc_567gddy0b98vly1w40000gn/T/ipykernel_47176/1871443153.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{short_prefix}_close_to_{long_prefix}_resistance'] = (short_close - long_resistance) / long_resistance\n",
      "/var/folders/m1/5dpmkc_567gddy0b98vly1w40000gn/T/ipykernel_47176/1871443153.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{short_prefix}_close_to_{long_prefix}_support'] = (short_close - long_support) / long_support\n",
      "/var/folders/m1/5dpmkc_567gddy0b98vly1w40000gn/T/ipykernel_47176/1871443153.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{short_prefix}_close_to_{long_prefix}_resistance'] = (short_close - long_resistance) / long_resistance\n",
      "[LightGBM] [Fatal] The number of features in data (125) is not the same as it was in training data (95).\n",
      "You can set ``predict_disable_shape_check=true`` to discard this error, but please be aware what you are doing.\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "The number of features in data (125) is not the same as it was in training data (95).\nYou can set ``predict_disable_shape_check=true`` to discard this error, but please be aware what you are doing.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 238\u001b[0m\n\u001b[1;32m    235\u001b[0m bb_middle \u001b[39m=\u001b[39m data_row[\u001b[39m'\u001b[39m\u001b[39m1T_BB_MIDDLE\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    237\u001b[0m \u001b[39m# Make a prediction with the model\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m y_pred \u001b[39m=\u001b[39m predict(data_row)\n\u001b[1;32m    240\u001b[0m \u001b[39m# Exit\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[39mif\u001b[39;00m portfolio[\u001b[39m'\u001b[39m\u001b[39mposition\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 33\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(data_row)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39m# Reshape the data_row into the correct format\u001b[39;00m\n\u001b[1;32m     32\u001b[0m data_row \u001b[39m=\u001b[39m data_row\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m prediction_proba \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(data_row)\n\u001b[1;32m     34\u001b[0m predicted_class \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m prob \u001b[39m>\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m prob \u001b[39min\u001b[39;00m prediction_proba]\n\u001b[1;32m     36\u001b[0m \u001b[39mreturn\u001b[39;00m predicted_class[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/dev/python/gmo-algo-trading/myenv/lib/python3.11/site-packages/lightgbm/basic.py:3538\u001b[0m, in \u001b[0;36mBooster.predict\u001b[0;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, **kwargs)\u001b[0m\n\u001b[1;32m   3536\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3537\u001b[0m         num_iteration \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m-> 3538\u001b[0m \u001b[39mreturn\u001b[39;00m predictor\u001b[39m.\u001b[39;49mpredict(data, start_iteration, num_iteration,\n\u001b[1;32m   3539\u001b[0m                          raw_score, pred_leaf, pred_contrib,\n\u001b[1;32m   3540\u001b[0m                          data_has_header, is_reshape)\n",
      "File \u001b[0;32m~/dev/python/gmo-algo-trading/myenv/lib/python3.11/site-packages/lightgbm/basic.py:848\u001b[0m, in \u001b[0;36m_InnerPredictor.predict\u001b[0;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[1;32m    846\u001b[0m     preds, nrow \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__pred_for_csc(data, start_iteration, num_iteration, predict_type)\n\u001b[1;32m    847\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, np\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m--> 848\u001b[0m     preds, nrow \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__pred_for_np2d(data, start_iteration, num_iteration, predict_type)\n\u001b[1;32m    849\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    850\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/dev/python/gmo-algo-trading/myenv/lib/python3.11/site-packages/lightgbm/basic.py:938\u001b[0m, in \u001b[0;36m_InnerPredictor.__pred_for_np2d\u001b[0;34m(self, mat, start_iteration, num_iteration, predict_type)\u001b[0m\n\u001b[1;32m    936\u001b[0m     \u001b[39mreturn\u001b[39;00m preds, nrow\n\u001b[1;32m    937\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 938\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_predict(mat, start_iteration, num_iteration, predict_type)\n",
      "File \u001b[0;32m~/dev/python/gmo-algo-trading/myenv/lib/python3.11/site-packages/lightgbm/basic.py:908\u001b[0m, in \u001b[0;36m_InnerPredictor.__pred_for_np2d.<locals>.inner_predict\u001b[0;34m(mat, start_iteration, num_iteration, predict_type, preds)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mWrong length of pre-allocated predict array\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    907\u001b[0m out_num_preds \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int64(\u001b[39m0\u001b[39m)\n\u001b[0;32m--> 908\u001b[0m _safe_call(_LIB\u001b[39m.\u001b[39;49mLGBM_BoosterPredictForMat(\n\u001b[1;32m    909\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m    910\u001b[0m     ptr_data,\n\u001b[1;32m    911\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(type_ptr_data),\n\u001b[1;32m    912\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int32(mat\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m]),\n\u001b[1;32m    913\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int32(mat\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m]),\n\u001b[1;32m    914\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(C_API_IS_ROW_MAJOR),\n\u001b[1;32m    915\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(predict_type),\n\u001b[1;32m    916\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(start_iteration),\n\u001b[1;32m    917\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(num_iteration),\n\u001b[1;32m    918\u001b[0m     c_str(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpred_parameter),\n\u001b[1;32m    919\u001b[0m     ctypes\u001b[39m.\u001b[39;49mbyref(out_num_preds),\n\u001b[1;32m    920\u001b[0m     preds\u001b[39m.\u001b[39;49mctypes\u001b[39m.\u001b[39;49mdata_as(ctypes\u001b[39m.\u001b[39;49mPOINTER(ctypes\u001b[39m.\u001b[39;49mc_double))))\n\u001b[1;32m    921\u001b[0m \u001b[39mif\u001b[39;00m n_preds \u001b[39m!=\u001b[39m out_num_preds\u001b[39m.\u001b[39mvalue:\n\u001b[1;32m    922\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mWrong length for predict results\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/dev/python/gmo-algo-trading/myenv/lib/python3.11/site-packages/lightgbm/basic.py:125\u001b[0m, in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check the return value from C API call.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \n\u001b[1;32m    119\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39m    The return value from C API calls.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 125\u001b[0m     \u001b[39mraise\u001b[39;00m LightGBMError(_LIB\u001b[39m.\u001b[39mLGBM_GetLastError()\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[0;31mLightGBMError\u001b[0m: The number of features in data (125) is not the same as it was in training data (95).\nYou can set ``predict_disable_shape_check=true`` to discard this error, but please be aware what you are doing."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "import mplfinance as mpf\n",
    "from ipywidgets import interact, widgets\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the path to the system path\n",
    "lib_path = os.path.abspath(os.path.join('lib'))\n",
    "sys.path.append(lib_path)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "def load_data(file_names):\n",
    "    dfs = []\n",
    "    for file_name in file_names:\n",
    "        df = pd.read_csv(file_name, index_col=\"date\")\n",
    "        dfs.append(df)\n",
    "    return dfs\n",
    "\n",
    "def predict(data_row):\n",
    "    if \"5T_target\" in data_row.index:\n",
    "        data_row = data_row.drop(\"5T_target\")\n",
    "    \n",
    "    # Reshape the data_row into the correct format\n",
    "    data_row = data_row.values.reshape(1, -1)\n",
    "    prediction_proba = model.predict(data_row)\n",
    "    predicted_class = [1 if prob > 0.5 else 0 for prob in prediction_proba]\n",
    "\n",
    "    return predicted_class[0]\n",
    "\n",
    "# feature engineering\n",
    "def feature_engineering(df, prefix):\n",
    "    open = df[f'{prefix}_open'].values\n",
    "    high = df[f'{prefix}_high'].values\n",
    "    low = df[f'{prefix}_low'].values\n",
    "    close = df[f'{prefix}_close'].values\n",
    "    # volume = df[f'{prefix}_volume'].values\n",
    "    hilo = (high + low) / 2\n",
    "\n",
    "    rsi = talib.RSI(close, timeperiod=8) # default = 14\n",
    "    df[f'{prefix}_RSI'] = rsi\n",
    "    df[f'{prefix}_RSI_BB_UPPER'], df[f'{prefix}_RSI_BB_MIDDLE'], df[f'{prefix}_RSI_BB_LOWER'] = talib.BBANDS(rsi, timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)\n",
    "    \n",
    "    df[f'{prefix}_RSI_ST'] = talib.RSI(close)/close\n",
    "    df[f'{prefix}_RSI_LOG'] = log_transform_feature(talib.RSI(close))\n",
    "    df[f'{prefix}_MACD'], _, _ = talib.MACD(close)\n",
    "    df[f'{prefix}_MACD_ST'], _, _ = talib.MACD(close)/close\n",
    "    df[f'{prefix}_ATR'] = talib.ATR(high, low, close)\n",
    "    df[f'{prefix}_ADX'] = talib.ADX(high, low, close, timeperiod=14)\n",
    "    df[f'{prefix}_ADXR'] = talib.ADXR(high, low, close, timeperiod=14)\n",
    "    \n",
    "    df[f'{prefix}_SMA20'] = talib.SMA(close, timeperiod=20)\n",
    "    df[f'{prefix}_SMA50'] = talib.SMA(close, timeperiod=50)\n",
    "    df[f'{prefix}_SMA100'] = talib.SMA(close, timeperiod=100)\n",
    "    \n",
    "    df[f'{prefix}_BB_UPPER'], df[f'{prefix}_BB_MIDDLE'], df[f'{prefix}_BB_LOWER'] = talib.BBANDS(close, timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)\n",
    "    df[f'{prefix}_BBANDS_upperband'] = (df[f'{prefix}_BB_UPPER'] - hilo) / close\n",
    "    df[f'{prefix}_BBANDS_middleband'] = (df[f'{prefix}_BB_MIDDLE'] - hilo) / close\n",
    "    df[f'{prefix}_BBANDS_lowerband'] = (df[f'{prefix}_BB_LOWER'] - hilo) / close\n",
    "    # df[f'{prefix}_BBANDS_bandwidth'] = (df[f'{prefix}_BB_UPPER'] - df[f'{prefix}_BB_LOWER']) / df[f'{prefix}_BB_MIDDLE']\n",
    "    # df[f'{prefix}_BBANDS_squeeze'] = (df[f'{prefix}_BBANDS_bandwidth'] < df[f'{prefix}_BBANDS_bandwidth'].rolling(window=20).mean()).astype(int)\n",
    "\n",
    "    df[f'{prefix}_STOCH_K'], df[f'{prefix}_STOCH_D'] = talib.STOCH(high, low, close)/close\n",
    "    df[f'{prefix}_MON'] = talib.MOM(close, timeperiod=5)\n",
    "    # df[f'{prefix}_OBV'] = talib.OBV(close, volume)\n",
    "\n",
    "    df[f'{prefix}_support'] = df[f'{prefix}_low'].rolling(window=20, min_periods=1).min()\n",
    "    df[f'{prefix}_resistance'] = df[f'{prefix}_high'].rolling(window=20, min_periods=1).max()\n",
    "\n",
    "    df = df.fillna(method='ffill')\n",
    "\n",
    "    return df\n",
    "\n",
    "def log_transform_feature(X):\n",
    "    X[X <= 0] = np.finfo(float).eps\n",
    "    return np.log(X)\n",
    "\n",
    "def create_label(df, prefix, lookbehind=1):\n",
    "    df[f'{prefix}_target'] = (df[f'{prefix}_close'] > df[f'{prefix}_close'].shift(lookbehind)).astype(int)\n",
    "    df = df.fillna(method='ffill')\n",
    "    return df\n",
    "\n",
    "def price_relation(df, short_prefix, long_prefix):\n",
    "    short_close = df[f'{short_prefix}_close']\n",
    "    long_support = df[f'{long_prefix}_support']\n",
    "    long_resistance = df[f'{long_prefix}_resistance']\n",
    "    df[f'{short_prefix}_close_to_{long_prefix}_support'] = (short_close - long_support) / long_support\n",
    "    df[f'{short_prefix}_close_to_{long_prefix}_resistance'] = (short_close - long_resistance) / long_resistance\n",
    "    return df\n",
    "\n",
    "def summarize_trade_results(trade_results):\n",
    "    num_trades = len(trade_results['profits'])\n",
    "    num_wins = sum(1 for x in trade_results['profits'] if x > 0)\n",
    "    num_losses = num_trades - num_wins\n",
    "\n",
    "    total_return = sum(trade_results['profits'])\n",
    "\n",
    "    average_win = sum(x for x in trade_results['profits'] if x > 0) / num_wins if num_wins > 0 else 0\n",
    "    average_loss = sum(x for x in trade_results['profits'] if x < 0) / num_losses if num_losses > 0 else 0\n",
    "\n",
    "    profit_factor = -average_win / average_loss if average_loss != 0 else 0\n",
    "\n",
    "    long_win_rate = sum(1 for x in trade_results['long_profits'] if x > 0) / len(trade_results['long_profits']) if trade_results['long_profits'] else 0\n",
    "    short_win_rate = sum(1 for x in trade_results['short_profits'] if x > 0) / len(trade_results['short_profits']) if trade_results['short_profits'] else 0\n",
    "\n",
    "    # Create cumulative return series\n",
    "    cumulative_returns = np.cumsum(trade_results['profits'])\n",
    "    cumulative_long_returns = np.cumsum(trade_results['long_profits'])\n",
    "    cumulative_short_returns = np.cumsum(trade_results['short_profits'])\n",
    "\n",
    "    # Calculate maximum drawdown using numpy\n",
    "    cumulative_max = np.maximum.accumulate(cumulative_returns)\n",
    "    non_zero_max = cumulative_max > 0\n",
    "    drawdowns = np.full_like(cumulative_returns, fill_value=0)\n",
    "    drawdowns[non_zero_max] = 1 - cumulative_returns[non_zero_max] / cumulative_max[non_zero_max]\n",
    "    max_drawdown = np.max(drawdowns)\n",
    "    maximum_single_trade_loss = min(trade_results['profits']) if trade_results['profits'] else 0\n",
    "\n",
    "    # Print the statistics\n",
    "    print(f\"Total Return: {total_return:.2f}\")\n",
    "    print(f\"Total Trade Num: {len(trade_results['profits'])}\")\n",
    "    print(f\"Max Drawdown: {max_drawdown * 100:.2f}%\")\n",
    "    print(f\"Max Single Trade Loss: {maximum_single_trade_loss:.2f}\")\n",
    "    print(f\"Profit Factor: {profit_factor:.2f}\")\n",
    "    print(f\"Long Trade Num: {len(trade_results['long_profits'])}\")\n",
    "    print(f\"Long Win Rate: {long_win_rate * 100:.2f}%\")\n",
    "    print(f\"Short Trade Num: {len(trade_results['short_profits'])}\")\n",
    "    print(f\"Short Win Rate: {short_win_rate * 100:.2f}%\")\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(cumulative_returns, label='Total Returns')\n",
    "    plt.title(\"Cumulative Total Returns\")\n",
    "    plt.xlabel(\"Trade\")\n",
    "    plt.ylabel(\"Cumulative Return\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(cumulative_long_returns, label='Long Returns', color='blue')\n",
    "    plt.plot(cumulative_short_returns, label='Short Returns', color='red')\n",
    "    plt.title(\"Cumulative Long and Short Returns\")\n",
    "    plt.xlabel(\"Trade\")\n",
    "    plt.ylabel(\"Cumulative Return\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def calc_trade_fee(price):\n",
    "    fee_rate = 0.001\n",
    "    return price * fee_rate\n",
    "\n",
    "def resample_data(df):    \n",
    "    # Convert the index to datetime\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    # Resample data to different timeframes\n",
    "    timeframes = ['1T', '5T', '15T', '30T']\n",
    "\n",
    "    resampled_dfs = []\n",
    "\n",
    "    for tf in timeframes:\n",
    "        resampled = df.resample(tf).agg({'open': 'first', 'high': 'max', 'low': 'min', 'close': 'last'})\n",
    "        resampled.dropna(inplace=True)\n",
    "        resampled.columns = [f\"{tf}_{col}\" for col in resampled.columns]  # df.columns -> resampled.columns\n",
    "        prefix = resampled.columns[0].split('_')[0]\n",
    "        processed_df = feature_engineering(resampled, prefix)\n",
    "        processed_df = create_label(processed_df, prefix)\n",
    "        resampled_dfs.append(processed_df)\n",
    "\n",
    "    # Combine resampled data\n",
    "    combined_resampled = pd.concat(resampled_dfs, axis=1).fillna(0)\n",
    "    return combined_resampled\n",
    "\n",
    "\n",
    "def initPortfolio():\n",
    "    portfolio = {\n",
    "        'position': None,  # \"long\" or \"short\"\n",
    "        'entry_price': None,\n",
    "        'entry_point': 0\n",
    "    }\n",
    "    return portfolio\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time() \n",
    "\n",
    "    file_names = [\"test_combined_data.csv\"]\n",
    "    dfs = load_data(file_names)\n",
    "\n",
    "    # Assuming you have only one DataFrame in the list\n",
    "    combined_df = dfs[0]\n",
    "    combined_df = resample_data(combined_df)\n",
    "\n",
    "    # add feature support and resistance\n",
    "    combined_df = price_relation(combined_df, '1T', '5T')\n",
    "    combined_df = price_relation(combined_df, '5T', '15T')\n",
    "    combined_df = price_relation(combined_df, '5T', '30T')\n",
    "\n",
    "    model_path = \"model/5m_model.pkl\"\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    # Initialize trade_results\n",
    "    trade_results = {\n",
    "        'profits': [],\n",
    "        'long_profits': [],\n",
    "        'short_profits': [],\n",
    "    }\n",
    "\n",
    "    # Initialize portfolio state\n",
    "    portfolio = initPortfolio()\n",
    "\n",
    "    # Loop through the data\n",
    "    for i in range(0, len(combined_df)):\n",
    "        profit = 0\n",
    "\n",
    "        # Get the current row of data\n",
    "        data_row = combined_df.iloc[i]\n",
    "        prev_row = combined_df.iloc[i-1]\n",
    "\n",
    "        # Retrieve the RSI and Bollinger Bands from the row\n",
    "        rsi = data_row['1T_RSI']\n",
    "        rsi_prev = prev_row['1T_RSI']\n",
    "        rsi_upper = data_row['1T_RSI_BB_UPPER']\n",
    "        rsi_lower = data_row['1T_RSI_BB_LOWER']\n",
    "        bb_upper = data_row['1T_BB_UPPER']\n",
    "        bb_lower = data_row['1T_BB_LOWER']\n",
    "        bb_middle = data_row['1T_BB_MIDDLE']\n",
    "\n",
    "        # Make a prediction with the model\n",
    "        y_pred = predict(data_row)\n",
    "\n",
    "        # Exit\n",
    "        if portfolio['position'] is not None:\n",
    "            if portfolio['position'] == 'long':\n",
    "                if data_row['1T_high'] >= bb_upper:\n",
    "\n",
    "                    profit = data_row['1T_close'] - portfolio['entry_price']\n",
    "                    trade_results['profits'].append(profit)\n",
    "                    trade_results['long_profits'].append(profit)\n",
    "                    portfolio = initPortfolio()\n",
    "                \n",
    "                else:\n",
    "                    trade_results['profits'].append(0)\n",
    "            elif portfolio['position'] == 'short':\n",
    "                if data_row['1T_low'] <= bb_lower:\n",
    "                    \n",
    "                    profit = portfolio['entry_price'] - data_row['1T_close']\n",
    "                    trade_results['profits'].append(profit)\n",
    "                    trade_results['short_profits'].append(profit)\n",
    "                    portfolio = initPortfolio()\n",
    "\n",
    "                else:\n",
    "                    trade_results['profits'].append(0)\n",
    "            else:\n",
    "                trade_results['profits'].append(0)\n",
    "        \n",
    "        # Short Entry\n",
    "        # elif rsi_prev > rsi_upper and rsi < rsi_upper:\n",
    "        #     # if y_pred == 0:\n",
    "        #         trade_results['profits'].append(0)\n",
    "        #         portfolio = {\n",
    "        #             'position': 'short',\n",
    "        #             'entry_price': data_row['1T_close'],\n",
    "        #             'entry_point': i\n",
    "        #         }\n",
    "\n",
    "        # Long Entry\n",
    "        elif rsi_prev < rsi_lower and rsi > rsi_lower:\n",
    "            # if y_pred == 1:\n",
    "                trade_results['profits'].append(0)\n",
    "                portfolio = {\n",
    "                    'position': 'long',\n",
    "                    'entry_price': data_row['1T_close'],\n",
    "                    'entry_point': i\n",
    "                }\n",
    "\n",
    "        else:\n",
    "            trade_results['profits'].append(0)\n",
    "\n",
    "    summarize_trade_results(trade_results)\n",
    "\n",
    "    # plot ====\n",
    "    def plot_candlestick(start, end):\n",
    "        start = pd.to_datetime(start)\n",
    "        end = pd.to_datetime(end)\n",
    "        \n",
    "        plot_df = combined_df.loc[start:end]\n",
    "        ohlc_df = plot_df[['1T_open', '1T_high', '1T_low', '1T_close']]\n",
    "        ohlc_df.columns = ['open', 'high', 'low', 'close']\n",
    "        \n",
    "        mpf.plot(ohlc_df, type='line', style='yahoo', volume=False, tight_layout=True, warn_too_much_data=7000000)\n",
    "\n",
    "    start_date = widgets.DatePicker(\n",
    "        description='Start Date',\n",
    "        value=pd.to_datetime(combined_df.index.min()),\n",
    "        disabled=False\n",
    "    )\n",
    "\n",
    "    end_date = widgets.DatePicker(\n",
    "        description='End Date',\n",
    "        value=pd.to_datetime(combined_df.index.max()),\n",
    "        disabled=False\n",
    "    )\n",
    "\n",
    "    interact(plot_candlestick, start=start_date, end=end_date)\n",
    "    # plot ====\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    minutes, seconds = divmod(elapsed_time, 60)\n",
    "    print(f\"Execution time: {int(minutes)} minutes {seconds:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
